{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48313b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codiri/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "from training.train import train_model, train_protonet\n",
    "from utils.transforms import get_transforms, get_imagenet_transforms, get_tiny_imagenet_transforms\n",
    "from utils.evaluation import evaluate_model\n",
    "from models.ResNet_SC import ModifiedResNet18#, ModifiedResNet50\n",
    "from models.ResNet import ResNet18, ResNet50\n",
    "from models.ProtoNet import ProtoNet18\n",
    "from models.FILM import FiLMNet18_SGC, FiLMNet50_SGC\n",
    "from dataset.Image_Classification import ImgClassificationDataset, ImgClassificationDatasetHF, CIFAR10C, FewShotDataset, ImageNetC, load_cifar10\n",
    "\n",
    "from models.TopoConv import TopoResNet18\n",
    "from models.SimpConv import ExpandedSimplicialResNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6a4362",
   "metadata": {},
   "source": [
    "train FiLM\n",
    "train Protonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd2ae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "lr = 0.0005\n",
    "num_classes = 10\n",
    "\n",
    "#loss_fn = \"ce\"\n",
    "use_koleo_loss = True\n",
    "\n",
    "CIFAR10C_ROOT = \"./data/cifar/CIFAR-10-C\"\n",
    "\n",
    "# List of all 15 corruption names in CIFAR-10-C (standard ordering)\n",
    "corruptions = [\n",
    "\t\"gaussian_noise\", \"shot_noise\", \"impulse_noise\",\n",
    "\t\"defocus_blur\", \"glass_blur\", \"motion_blur\", \"zoom_blur\",\n",
    "\t\"snow\", \"frost\", \"fog\", \"brightness\",\n",
    "\t\"contrast\", \"elastic_transform\", \"pixelate\",\n",
    "\t\"jpeg_compression\"\n",
    "]\n",
    "\n",
    "# Select device: prefer CUDA, then Apple MPS (for Apple Silicon), otherwise CPU\n",
    "if torch.cuda.is_available():\n",
    "\tdevice = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "\tdevice = torch.device(\"mps\")\n",
    "else:\n",
    "\tdevice = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf5023",
   "metadata": {},
   "source": [
    "## 1) Load data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0121d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column([<PIL.PngImagePlugin.PngImageFile image mode=RGB size=213x160 at 0x13ECFA7B0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x243 at 0x13ECF8500>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x213 at 0x13F91CC20>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x213 at 0x13F91DA60>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=213x160 at 0x13F91D040>])\n"
     ]
    }
   ],
   "source": [
    "train_transform = get_transforms(split='train')\n",
    "test_transform = get_transforms(split='test')\n",
    "\n",
    "imagenet_train_transform = get_imagenet_transforms(split='train')\n",
    "imagenet_test_transform = get_imagenet_transforms(split='test')\n",
    "\n",
    "t_imagenet_train_transform = get_tiny_imagenet_transforms(split='train')\n",
    "t_imagenet_test_transform = get_tiny_imagenet_transforms(split='test')\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\n",
    "\troot=\"./data\",          \n",
    "\ttrain=True,             \n",
    "\tdownload=True,          \n",
    "\ttransform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "\troot=\"./data\",\n",
    "\ttrain=False,\n",
    "\tdownload=True,\n",
    "\ttransform=test_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "\ttrain_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tshuffle=True,    \n",
    "\tnum_workers=2     \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "\ttest_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tshuffle=False,  \n",
    "\tnum_workers=2\n",
    ")\n",
    "\n",
    "# load ImageNet\n",
    "\"\"\"\n",
    "imagenet_train_dataset = datasets.ImageFolder(\n",
    "\troot=\"./data/imagenet/imagenet/train\",\n",
    "\ttransform=imagenet_train_transform,\n",
    ")\n",
    "\n",
    "imagenet_test_dataset = datasets.ImageFolder(\n",
    "\troot=\"./data/imagenet/imagenet/train\",\n",
    "\ttransform=imagenet_test_transform\n",
    ")\n",
    "\n",
    "imagenet_train_loader = DataLoader(\n",
    "\timagenet_train_dataset,\n",
    "\tbatch_size=128,\n",
    "\tshuffle=True,         \n",
    ")\n",
    "\n",
    "imagenet_test_loader = DataLoader(\n",
    "\timagenet_test_dataset,\n",
    "\tbatch_size=128,\n",
    "\tshuffle=False,     \n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# load tiny-imagenet\n",
    "t_imagenet_data = load_dataset(\"clane9/imagenet-100\")\n",
    "\n",
    "train_t_imagenet_data = t_imagenet_data[\"train\"]\n",
    "val_t_imagenet_data = t_imagenet_data[\"validation\"]\n",
    "print(train_t_imagenet_data['image'])\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "\timg = train_t_imagenet_data[i]['image']\n",
    "\taxs[i].imshow(img)\n",
    "\taxs[i].axis('off')\n",
    "\taxs[i].set_title(f\"Label: {train_t_imagenet_data[i]['label']}\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "train_t_imagenet_ds = ImgClassificationDataset(\n",
    "\tdata = train_t_imagenet_data[\"image\"],\n",
    "\tlabels = train_t_imagenet_data[\"label\"],\n",
    "\ttransform = imagenet_train_transform\n",
    ")\n",
    "\n",
    "val_t_imagenet_ds = ImgClassificationDataset(\n",
    "\tdata = val_t_imagenet_data[\"image\"],\n",
    "\tlabels = val_t_imagenet_data[\"label\"],\n",
    "\ttransform = imagenet_test_transform\n",
    ")\n",
    "\n",
    "train_t_imagenet_loader = DataLoader(\n",
    "\ttrain_t_imagenet_ds,\n",
    "\tbatch_size=32,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=2\n",
    ")\n",
    "val_t_imagenet_loader = DataLoader(\n",
    "\tval_t_imagenet_ds,\n",
    "\tbatch_size=32,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=2\n",
    ")\n",
    "\n",
    "# Load Tiny-ImageNet-C\n",
    "\"\"\"\n",
    "t_imagenet_dataset_c = ImageNetC(\n",
    "\troot_dir=\"./data/imagenet/Tiny-ImageNet-C\",)\n",
    "\n",
    "t_imagenet_loader_c = DataLoader(\n",
    "\tt_imagenet_dataset_c,\n",
    "\tbatch_size=32,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=2\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# cifar10 loader for few-shot learning\n",
    "cifar10_train_imgs, cifar10_train_labels = load_cifar10(data_dir=\"./data/cifar-10-batches-py\", train=True, img_size=32)\n",
    "cifar10_test_imgs, cifar10_test_labels = load_cifar10(data_dir=\"./data/cifar-10-batches-py\", train=False, img_size=32)\n",
    "\n",
    "protonet_train_dataset = FewShotDataset(data=train_t_imagenet_data[\"image\"], labels=train_t_imagenet_data[\"label\"], n_classes=5, n_supp=5, n_queries=10, transform=train_transform)\n",
    "protonet_test_dataset = FewShotDataset(data=val_t_imagenet_data[\"image\"], labels=val_t_imagenet_data[\"label\"], n_classes=5, n_supp=5, n_queries=10, transform=train_transform)\n",
    "\n",
    "protonet_train_loader = DataLoader(protonet_train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "protonet_test_loader = DataLoader(protonet_test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7034e4",
   "metadata": {},
   "source": [
    "## 2) Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c25fa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain ResNet-50: ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "ResNet-50 with AdaBN: ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "ResNet-50 with CBAM: ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=8, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=8, out_features=128, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=8, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=8, out_features=128, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "ResNet-50 with Prototype Alignment: ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codiri/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/codiri/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# (1) Plain ResNet-50 (no self-correction)\n",
    " \n",
    "model_plain = ResNet18(\n",
    "\tnum_classes=num_classes,\n",
    "\tuse_adabn=False,\n",
    "\tuse_cbam=False,\n",
    "\tuse_proto=False,\n",
    "\tuse_rbn=False,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# (2) ResNet-50 + AdaBN\n",
    "model_adabn = ResNet18(\n",
    "\tnum_classes=num_classes,\n",
    "\tuse_adabn=True,\n",
    "\tuse_cbam=False,\n",
    "\tuse_proto=False,\n",
    "\tuse_rbn=False,\n",
    ").to(device)\n",
    "\n",
    "# (3) ResNet-50 + CBAM\n",
    "model_cbam = ResNet18(\n",
    "\tnum_classes=num_classes,\n",
    "\tuse_adabn=False,\n",
    "\tuse_cbam=True,\n",
    "\tuse_proto=False,\n",
    "\tuse_rbn=False,\n",
    ").to(device)\n",
    "\n",
    "# (4) ResNet-50 + Prototype Alignment\n",
    "model_proto = ResNet18(\n",
    "\tnum_classes=num_classes,\n",
    "\tuse_adabn=False,\n",
    "\tuse_cbam=False,\n",
    "\tuse_proto=True,\n",
    "\tuse_rbn=False,\n",
    ").to(device)\n",
    "\n",
    "print(f\"Plain ResNet-50: {model_plain}\")\n",
    "print(f\"ResNet-50 with AdaBN: {model_adabn}\")\n",
    "print(f\"ResNet-50 with CBAM: {model_cbam}\")\n",
    "print(f\"ResNet-50 with Prototype Alignment: {model_proto}\")\n",
    "\"\"\"\n",
    "model_resnet18 = ResNet18(num_classes=10).to(device)\n",
    "model_resnet50 = ResNet50(num_classes=10).to(device)\n",
    "model_filmnet18_sgc = FiLMNet18_SGC(c_dim=512, num_classes=num_classes).to(device)\n",
    "model_filmnet50_sgc = FiLMNet50_SGC(c_dim=512, num_classes=1000).to(device)\n",
    "model_protonet18 = ProtoNet18(ResNet18, embedding_dim=512, num_classes=num_classes).to(device)\n",
    "model_protonet50 = ProtoNet18(ResNet50, embedding_dim=2048, num_classes=num_classes).to(device)\n",
    "print(model_resnet18)\n",
    "\"\"\"\n",
    "\n",
    "# geometric models, kind of\n",
    "\n",
    "model_topo_conv = TopoResNet18(num_classes=num_classes).to(device)\n",
    "model_simp_conv = ExpandedSimplicialResNet(num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5363b",
   "metadata": {},
   "source": [
    "### 2.1) Model optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2921447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optim_resnet18  = optim.AdamW(model_resnet18.parameters(), lr=lr, weight_decay=5e-4)\n",
    "#optim_resnet50  = optim.AdamW(model_resnet50.parameters(), lr=lr, weight_decay=5e-4)\n",
    "#optim_protonet18 = optim.AdamW(model_protonet18.parameters(), lr=lr, weight_decay=5e-4)\n",
    "#optim_filmnet18_sgc = optim.AdamW(model_filmnet18_sgc.parameters(), lr=lr, weight_decay=5e-4)\n",
    "#optim_filmnet50_sgc = optim.AdamW(model_filmnet50_sgc.parameters(), lr=lr, weight_decay=5e-4)\n",
    "optim_plain  = optim.SGD(model_plain.parameters(),  lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optim_adabn  = optim.SGD(model_adabn.parameters(),  lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optim_cbam   = optim.SGD(model_cbam.parameters(),   lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optim_proto  = optim.SGD(model_proto.parameters(),  lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optim_topo_conv = optim.SGD(model_topo_conv.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optim_simp_conv = optim.SGD(model_simp_conv.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# A dictionary to store (model, optimizer) pairs for easy looping:\n",
    "baseline_dict = {\n",
    "#    \"ResNet18\": (model_resnet18, optim_resnet18),\n",
    "#    \"ResNet50\": (model_resnet50, optim_resnet50),\n",
    "#\t\"ProtoNet18\": (model_protonet18, optim_protonet18),\n",
    "\t\"Proto\"   : (model_proto, optim_proto),\n",
    "\t\"Plain\"   : (model_plain, optim_plain),\n",
    "\t\"AdaBN\"   : (model_adabn, optim_adabn),\n",
    "\t\"CBAM\"    : (model_cbam,  optim_cbam ),\n",
    "#\t\"TopoConv\": (model_topo_conv, optim_topo_conv),\n",
    "#\t\"SimpConv\": (model_simp_conv, optim_simp_conv),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ed0d7",
   "metadata": {},
   "source": [
    "## 3) Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acab78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training baseline: TopoConv ===\n",
      "\n",
      "Batch idx: 0 of 1563\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (4) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m best_val_acc = {name: \u001b[32m0.0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m baseline_dict.keys()}\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, (model, optim) \u001b[38;5;129;01min\u001b[39;00m baseline_dict.items():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \t\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m\t\t\t\t\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#train_protonet(name=\"ProtoNet\", model=model_protonet18, optimizer=optim_protonet18, train_loader=protonet_train_loader, test_loader=protonet_test_loader,\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#\t\t\tcriterion=criterion, device=device, num_epochs=num_epochs)\u001b[39;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#train_model(name=\"FilmNet50_SGC\", model=model_filmnet50_sgc, optimizer=optim_filmnet50_sgc, train_loader=train_t_imagenet_loader, test_loader=val_t_imagenet_loader,\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#\t\t\tcriterion=criterion, device=device, num_epochs=num_epochs)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University/Edinburgh/Lightweight-SCNNs/training/train.py:73\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(name, model, optimizer, train_loader, test_loader, criterion, device, num_epochs)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m#print(f\"Inputs shape: {inputs.shape}, Targets shape: {targets.shape}\")\u001b[39;00m\n\u001b[32m     72\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m feat, outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m#print(outputs.shape, targets.shape)\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m#cross entropy loss\u001b[39;00m\n\u001b[32m     76\u001b[39m ce_loss = ce_fn(outputs, targets)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University/Edinburgh/Lightweight-SCNNs/models/TopoConv.py:105\u001b[39m, in \u001b[36mTopoResNet18.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    102\u001b[39m x = \u001b[38;5;28mself\u001b[39m.maxpool(x)  \u001b[38;5;66;03m# [B, 64, H/4, W/4]\u001b[39;00m\n\u001b[32m    104\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer1(x)  \u001b[38;5;66;03m# [B, 64, H/4, W/4]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [B, 128, H/8, W/8]\u001b[39;00m\n\u001b[32m    106\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer3(x)  \u001b[38;5;66;03m# [B, 256, H/16, W/16]\u001b[39;00m\n\u001b[32m    107\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer4(x)  \u001b[38;5;66;03m# [B, 512, H/32, W/32]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University/Edinburgh/Lightweight-SCNNs/models/TopoConv.py:69\u001b[39m, in \u001b[36mTopoResNet18Block.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.downsample != \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     67\u001b[39m     identity = \u001b[38;5;28mself\u001b[39m.downsample(identity)  \u001b[38;5;66;03m# [B, out_channels, H/2, W/2]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43midentity\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (8) must match the size of tensor b (4) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Track best validation accuracy for each baseline:\n",
    "best_val_acc = {name: 0.0 for name in baseline_dict.keys()}\n",
    "\n",
    "#for name, (model, optim) in baseline_dict.items():\n",
    "#\ttrain_model(name=name, model=model, optimizer=optim, train_loader=train_loader, test_loader=test_loader, \n",
    "#\t\t\t\tcriterion=criterion, device=device, num_epochs=num_epochs)\n",
    "\n",
    "\n",
    "#train_protonet(name=\"ProtoNet\", model=model_protonet18, optimizer=optim_protonet18, train_loader=protonet_train_loader, test_loader=protonet_test_loader,\n",
    "#\t\t\tcriterion=criterion, device=device, num_epochs=num_epochs)\n",
    "\n",
    "#train_model(name=\"FilmNet50_SGC\", model=model_filmnet50_sgc, optimizer=optim_filmnet50_sgc, train_loader=train_t_imagenet_loader, test_loader=val_t_imagenet_loader,\n",
    "#\t\t\tcriterion=criterion, device=device, num_epochs=num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2cb595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e327993",
   "metadata": {},
   "source": [
    "### Save the models to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ba88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Dictionary mapping a human‐readable name → the actual nn.Module\\nmodels_to_save = {\\n\\t\"plain\":  model_plain,\\n\\t\"adabn\":  model_adabn,\\n\\t\"cbam\":   model_cbam,\\n\\t\"proto\":  model_proto,\\n}\\n\\n# Ensure the directory exists (in this case, we’re saving to the current working directory)\\nsave_dir = os.getcwd()\\nprint(f\"Saving models into: {save_dir}\")\\n\\nfor name, model in models_to_save.items():\\n\\t# Construct a filename like \"model_plain.pth\" or \"model_adabn.pth\"\\n\\tfilename = f\"model_{name}.pth\"\\n\\tfilepath = os.path.join(save_dir, filename)\\n\\n\\t# Save only the model’s state dict (weights + buffers)\\n\\ttorch.save(model.state_dict(), filepath)\\n\\tprint(f\"→ Saved {name} to {filename}\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Dictionary mapping a human‐readable name → the actual nn.Module\n",
    "models_to_save = {\n",
    "\t\"plain\":  model_plain,\n",
    "\t\"adabn\":  model_adabn,\n",
    "\t\"cbam\":   model_cbam,\n",
    "\t\"proto\":  model_proto,\n",
    "}\n",
    "\n",
    "# Ensure the directory exists (in this case, we’re saving to the current working directory)\n",
    "save_dir = os.getcwd()\n",
    "print(f\"Saving models into: {save_dir}\")\n",
    "\n",
    "for name, model in models_to_save.items():\n",
    "\t# Construct a filename like \"model_plain.pth\" or \"model_adabn.pth\"\n",
    "\tfilename = f\"model_{name}.pth\"\n",
    "\tfilepath = os.path.join(save_dir, filename)\n",
    "\n",
    "\t# Save only the model’s state dict (weights + buffers)\n",
    "\ttorch.save(model.state_dict(), filepath)\n",
    "\tprint(f\"→ Saved {name} to {filename}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4abecd",
   "metadata": {},
   "source": [
    "### Load models from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcdbfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded AdaBN model from /Users/codiri/University/Edinburgh/Lightweight-SCNNs/checkpoints/ckpt_epoch_120_AdaBN.pt\n",
      "Loaded CBAM model from /Users/codiri/University/Edinburgh/Lightweight-SCNNs/checkpoints/ckpt_epoch_120_CBAM.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Directory to save the models\n",
    "save_dir = os.getcwd()  # Current working directory\n",
    "\n",
    "\n",
    "for name, (model, optim) in baseline_dict.items():\n",
    "\tpath = os.path.join(save_dir, f\"checkpoints/ckpt_epoch_120_{name}.pt\")\n",
    "\tif os.path.exists(path):\n",
    "\t\tstate_dict = torch.load(path, map_location=device)\n",
    "\t\tmodel.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "\n",
    "\t\tprint(f\"Loaded {name} model from {path}\")\n",
    "\n",
    "\telse:\n",
    "\t\tprint(f\"File not found: {path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72dfa7",
   "metadata": {},
   "source": [
    "### 3.1) Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c833953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBN: Accuracy on Tiny-ImageNet val set = 20.86%\n",
      "CBAM: Accuracy on Tiny-ImageNet val set = 75.22%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate total accuracy on val_t_imagenet_loader for all 4 models\n",
    "accuracies = {}\n",
    "\n",
    "for name, (model, optim) in baseline_dict.items():\n",
    "\tmodel.eval()\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor images, labels in val_t_imagenet_loader:\n",
    "\t\t\timages = images.to(device)\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\t\t\tfeats, outputs = model(images)\n",
    "\t\t\t_, preds = outputs.max(dim=1)\n",
    "\t\t\tcorrect += (preds == labels).sum().item()\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\tacc = correct / total\n",
    "\taccuracies[name] = acc\n",
    "\tprint(f\"{name}: Accuracy on Tiny-ImageNet val set = {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feced7b",
   "metadata": {},
   "source": [
    "## 4) Evaluate model on CIFAR-10C dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771cc68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating corruption: gaussian_noise (severity=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codiri/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'max'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m labels = labels.to(device)\n\u001b[32m     35\u001b[39m outputs = model(images)               \u001b[38;5;66;03m# (B, 10)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m _, preds = \u001b[43moutputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m(dim=\u001b[32m1\u001b[39m)         \u001b[38;5;66;03m# (B,)\u001b[39;00m\n\u001b[32m     37\u001b[39m correct += (preds == labels).sum().item()\n\u001b[32m     38\u001b[39m total += labels.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'max'"
     ]
    }
   ],
   "source": [
    "severity = 1  # Severity level (1-5), where 1 is the least severe\n",
    "batch_size = 256\n",
    "\n",
    "# We'll store per-model, per-corruption accuracies here:\n",
    "results = { name: [] for name in baseline_dict.keys() }\n",
    "\n",
    "# For each corruption type, build a CIFAR10C loader and measure accuracy:\n",
    "for corruption in corruptions:\n",
    "\t# Create the CIFAR-10-C dataset for this corruption & severity\n",
    "\tprint(f\"\\nEvaluating corruption: {corruption} (severity={severity})\")\n",
    "\tds_c = CIFAR10C(\n",
    "\t\tdata_dir=CIFAR10C_ROOT,\n",
    "\t\tcorruption=corruption,\n",
    "\t\tseverity=severity,\n",
    "\t\ttransform=test_transform\n",
    "\t)\n",
    "\tloader_c = DataLoader(ds_c,\n",
    "\t\t\t\t\t\t  batch_size=batch_size,\n",
    "\t\t\t\t\t\t  shuffle=False,\n",
    "\t\t\t\t\t\t  num_workers=2,\n",
    "\t\t\t\t\t\t  pin_memory=True)\n",
    "\n",
    "\t# For each model, run inference on this loader and compute accuracy\n",
    "\tfor name, (model, optim) in baseline_dict.items():\n",
    "\t\t#print(f\"  Evaluating {name}...\", end='\\n')\n",
    "\t\tmodel.eval()  # Set model to evaluation mode\n",
    "\t\tcorrect = 0\n",
    "\t\ttotal = 0\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor images, labels in loader_c:\n",
    "\t\t\t\timages = images.to(device)\n",
    "\t\t\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\t\t\toutputs = model(images)               # (B, 10)\n",
    "\t\t\t\t_, preds = outputs.max(dim=1)         # (B,)\n",
    "\t\t\t\tcorrect += (preds == labels).sum().item()\n",
    "\t\t\t\ttotal += labels.size(0)\n",
    "\t\t\t\t#print(f\"  {name}: {correct}/{total} ({100 * correct / total:.2f}%)\", end='\\r')\n",
    "\n",
    "\t\tacc = correct / total\n",
    "\t\tresults[name].append(acc)\n",
    "\n",
    "\tprint(f\"Corruption = {corruption:<15} | \"\n",
    "\t\t  + \"  \".join([f\"{n}: {results[n][-1]*100:5.2f}%\" for n in baseline_dict.keys()]) )\n",
    "\n",
    "# 5) Summarize average across all corruptions\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"\\nAverage accuracy over all 15 corruptions (severity=1):\")\n",
    "for name in baseline_dict.keys():\n",
    "\tavg_acc = np.mean(results[name])\n",
    "\tprint(f\"  {name:<5}  →  {avg_acc*100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46281fc1",
   "metadata": {},
   "source": [
    "### 4.1) Load concatenated CIFAR-10C dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa1c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR-10-C corruption arrays...\n",
      "Corruption: gaussian_noise, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: shot_noise, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: impulse_noise, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: defocus_blur, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: glass_blur, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: motion_blur, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: zoom_blur, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: snow, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: frost, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: fog, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: brightness, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: contrast, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: elastic_transform, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: pixelate, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: jpeg_compression, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Concatenated array shape: (750000, 32, 32, 3), dtype: uint8\n",
      "Labels shape: (50000,), dtype: uint8\n",
      "All labels shape: (750000,), dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "# Load and inspect CIFAR-10-C corruption arrays\n",
    "print(\"Loading CIFAR-10-C corruption arrays...\")\n",
    "arr = []\n",
    "\n",
    "\n",
    "for corruption in corruptions:\n",
    "\tarr_c = np.load(os.path.join(CIFAR10C_ROOT, f\"{corruption}.npy\"))\n",
    "\tprint(f\"Corruption: {corruption}, shape: {arr_c.shape}, dtype: {arr_c.dtype}\")\n",
    "\n",
    "\t# concatanate all corruption arrays into a single tensor\n",
    "\tarr.append(arr_c)\n",
    "\n",
    "arr = np.concatenate(arr, axis=0)\n",
    "print(f\"Concatenated array shape: {arr.shape}, dtype: {arr.dtype}\")\n",
    "\n",
    "labels = np.load(os.path.join(CIFAR10C_ROOT, \"labels.npy\"))\n",
    "print(f\"Labels shape: {labels.shape}, dtype: {labels.dtype}\")\n",
    "all_labels = np.concatenate([labels] * len(corruptions), axis=0)\n",
    "print(f\"All labels shape: {all_labels.shape}, dtype: {all_labels.dtype}\")\n",
    "\n",
    "# Create a daatset from the concatenated array\n",
    "ds_cifar10c = ImgClassificationDataset(\n",
    "\tdata=arr,\n",
    "\tlabels=all_labels,\n",
    "\ttransform=test_transform\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the CIFAR-10-C dataset\n",
    "loader_cifar10c = DataLoader(\n",
    "\tds_cifar10c,\n",
    "\tbatch_size=batch_size,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa7179",
   "metadata": {},
   "source": [
    "### 4.2) Compute ECE over entire CIFAR-10-C dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972af11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Proto on CIFAR-10-C dataset...\n",
      "Processed 515680 / 750000 images\n",
      "ECE over CIFAR-10-C: 4.99%\n",
      "Accuracy over CIFAR-10-C: 79.99%\n",
      "Proto - Accuracy: 79.99%, ECE: 0.0499\n",
      "\n",
      "Evaluating Plain on CIFAR-10-C dataset...\n",
      "Processed 515680 / 750000 images\n",
      "ECE over CIFAR-10-C: 10.21%\n",
      "Accuracy over CIFAR-10-C: 76.07%\n",
      "Plain - Accuracy: 76.07%, ECE: 0.1021\n",
      "\n",
      "Evaluating AdaBN on CIFAR-10-C dataset...\n",
      "Processed 515680 / 750000 images\n",
      "ECE over CIFAR-10-C: 5.40%\n",
      "Accuracy over CIFAR-10-C: 81.75%\n",
      "AdaBN - Accuracy: 81.75%, ECE: 0.0540\n",
      "\n",
      "Evaluating CBAM on CIFAR-10-C dataset...\n",
      "Processed 515680 / 750000 images\n",
      "ECE over CIFAR-10-C: 15.18%\n",
      "Accuracy over CIFAR-10-C: 70.39%\n",
      "CBAM - Accuracy: 70.39%, ECE: 0.1518\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy and ECE for each model on the CIFAR-10-C dataset\n",
    "acc_list = []\n",
    "ece_list = []\n",
    "\n",
    "for name, (model, optim) in baseline_dict.items():\n",
    "\tprint(f\"\\nEvaluating {name} on CIFAR-10-C dataset...\")\n",
    "\tece, acc = evaluate_model(model=model,\n",
    "\t\t\t\t   loader=loader_cifar10c,\n",
    "\t\t\t\t   device=device)\n",
    "\tacc_list.append(acc)\n",
    "\tece_list.append(ece)\n",
    "\tprint(f\"{name} - Accuracy: {acc*100:.2f}%, ECE: {ece:.4f}\")\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe7648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
