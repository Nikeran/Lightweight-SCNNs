{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48313b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codiri/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "from training.train import train_model, train_protonet\n",
    "from utils.transforms import get_transforms, get_imagenet_transforms, get_tiny_imagenet_transforms\n",
    "from utils.evaluation import evaluate_model\n",
    "from models.ResNet_SC import ModifiedResNet18#, ModifiedResNet50\n",
    "from models.ResNet import ResNet18, ResNet50\n",
    "from models.ProtoNet import ProtoNet18\n",
    "from models.FILM import FiLMNet18_SGC, FiLMNet50_SGC\n",
    "from dataset.Image_Classification import ImgClassificationDataset, ImgClassificationDatasetHF, CIFAR10C, FewShotDataset, ImageNetC, load_cifar10\n",
    "\n",
    "from models.TopoConv import TopoResNet18\n",
    "from models.SimpConv import ExpandedSimplicialResNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6a4362",
   "metadata": {},
   "source": [
    "train FiLM\n",
    "train Protonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd2ae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "lr = 0.0005\n",
    "num_classes = 10\n",
    "\n",
    "#loss_fn = \"ce\"\n",
    "use_koleo_loss = True\n",
    "\n",
    "CIFAR10C_ROOT = \"./data/cifar/CIFAR-10-C\"\n",
    "\n",
    "# List of all 15 corruption names in CIFAR-10-C (standard ordering)\n",
    "corruptions = [\n",
    "\t\"gaussian_noise\", \"shot_noise\", \"impulse_noise\",\n",
    "\t\"defocus_blur\", \"glass_blur\", \"motion_blur\", \"zoom_blur\",\n",
    "\t\"snow\", \"frost\", \"fog\", \"brightness\",\n",
    "\t\"contrast\", \"elastic_transform\", \"pixelate\",\n",
    "\t\"jpeg_compression\"\n",
    "]\n",
    "\n",
    "# Select device: prefer CUDA, then Apple MPS (for Apple Silicon), otherwise CPU\n",
    "if torch.cuda.is_available():\n",
    "\tdevice = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "\tdevice = torch.device(\"mps\")\n",
    "else:\n",
    "\tdevice = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf5023",
   "metadata": {},
   "source": [
    "## 1) Load data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0121d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column([<PIL.PngImagePlugin.PngImageFile image mode=RGB size=213x160 at 0x175299E80>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x243 at 0x17529A0C0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x213 at 0x177D8F620>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x213 at 0x177D8FA40>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=213x160 at 0x177DA44A0>])\n"
     ]
    }
   ],
   "source": [
    "train_transform = get_transforms(split='train')\n",
    "test_transform = get_transforms(split='test')\n",
    "\n",
    "imagenet_train_transform = get_imagenet_transforms(split='train')\n",
    "imagenet_test_transform = get_imagenet_transforms(split='test')\n",
    "\n",
    "t_imagenet_train_transform = get_tiny_imagenet_transforms(split='train')\n",
    "t_imagenet_test_transform = get_tiny_imagenet_transforms(split='test')\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\n",
    "\troot=\"./data\",          \n",
    "\ttrain=True,             \n",
    "\tdownload=True,          \n",
    "\ttransform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "\troot=\"./data\",\n",
    "\ttrain=False,\n",
    "\tdownload=True,\n",
    "\ttransform=test_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "\ttrain_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tshuffle=True,    \n",
    "\tnum_workers=2     \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "\ttest_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tshuffle=False,  \n",
    "\tnum_workers=2\n",
    ")\n",
    "\n",
    "# load ImageNet\n",
    "\"\"\"\n",
    "imagenet_train_dataset = datasets.ImageFolder(\n",
    "\troot=\"./data/imagenet/imagenet/train\",\n",
    "\ttransform=imagenet_train_transform,\n",
    ")\n",
    "\n",
    "imagenet_test_dataset = datasets.ImageFolder(\n",
    "\troot=\"./data/imagenet/imagenet/train\",\n",
    "\ttransform=imagenet_test_transform\n",
    ")\n",
    "\n",
    "imagenet_train_loader = DataLoader(\n",
    "\timagenet_train_dataset,\n",
    "\tbatch_size=128,\n",
    "\tshuffle=True,         \n",
    ")\n",
    "\n",
    "imagenet_test_loader = DataLoader(\n",
    "\timagenet_test_dataset,\n",
    "\tbatch_size=128,\n",
    "\tshuffle=False,     \n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# load tiny-imagenet\n",
    "t_imagenet_data = load_dataset(\"clane9/imagenet-100\")\n",
    "\n",
    "train_t_imagenet_data = t_imagenet_data[\"train\"]\n",
    "val_t_imagenet_data = t_imagenet_data[\"validation\"]\n",
    "print(train_t_imagenet_data['image'])\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "\timg = train_t_imagenet_data[i]['image']\n",
    "\taxs[i].imshow(img)\n",
    "\taxs[i].axis('off')\n",
    "\taxs[i].set_title(f\"Label: {train_t_imagenet_data[i]['label']}\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "train_t_imagenet_ds = ImgClassificationDataset(\n",
    "\tdata = train_t_imagenet_data[\"image\"],\n",
    "\tlabels = train_t_imagenet_data[\"label\"],\n",
    "\ttransform = imagenet_train_transform\n",
    ")\n",
    "\n",
    "val_t_imagenet_ds = ImgClassificationDataset(\n",
    "\tdata = val_t_imagenet_data[\"image\"],\n",
    "\tlabels = val_t_imagenet_data[\"label\"],\n",
    "\ttransform = imagenet_test_transform\n",
    ")\n",
    "\n",
    "train_t_imagenet_loader = DataLoader(\n",
    "\ttrain_t_imagenet_ds,\n",
    "\tbatch_size=32,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=2\n",
    ")\n",
    "val_t_imagenet_loader = DataLoader(\n",
    "\tval_t_imagenet_ds,\n",
    "\tbatch_size=32,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=2\n",
    ")\n",
    "\n",
    "# Load Tiny-ImageNet-C\n",
    "\"\"\"\n",
    "t_imagenet_dataset_c = ImageNetC(\n",
    "\troot_dir=\"./data/imagenet/Tiny-ImageNet-C\",)\n",
    "\n",
    "t_imagenet_loader_c = DataLoader(\n",
    "\tt_imagenet_dataset_c,\n",
    "\tbatch_size=32,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=2\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# cifar10 loader for few-shot learning\n",
    "cifar10_train_imgs, cifar10_train_labels = load_cifar10(data_dir=\"./data/cifar-10-batches-py\", train=True, img_size=32)\n",
    "cifar10_test_imgs, cifar10_test_labels = load_cifar10(data_dir=\"./data/cifar-10-batches-py\", train=False, img_size=32)\n",
    "\n",
    "protonet_train_dataset = FewShotDataset(data=train_t_imagenet_data[\"image\"], labels=train_t_imagenet_data[\"label\"], n_classes=5, n_supp=5, n_queries=10, transform=train_transform)\n",
    "protonet_test_dataset = FewShotDataset(data=val_t_imagenet_data[\"image\"], labels=val_t_imagenet_data[\"label\"], n_classes=5, n_supp=5, n_queries=10, transform=train_transform)\n",
    "\n",
    "protonet_train_loader = DataLoader(protonet_train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "protonet_test_loader = DataLoader(protonet_test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7034e4",
   "metadata": {},
   "source": [
    "## 2) Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c25fa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain ResNet-50: ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "ResNet-50 with AdaBN: ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): AdaBatchNorm2d(\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "ResNet-50 with CBAM: ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=8, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=8, out_features=128, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=8, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=8, out_features=128, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM(\n",
      "        (c_at): ChannelAttention(\n",
      "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          )\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (s_at): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "ResNet-50 with Prototype Alignment: ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "    (1): ModifiedResNet18Block(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (proto): PrototypeAlignment()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codiri/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/codiri/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# (1) Plain ResNet-50 (no self-correction)\n",
    " \n",
    "model_plain = ResNet18(\n",
    "\tnum_classes=num_classes,\n",
    "\tuse_adabn=False,\n",
    "\tuse_cbam=False,\n",
    "\tuse_proto=False,\n",
    "\tuse_rbn=False,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# (2) ResNet-50 + AdaBN\n",
    "model_adabn = ResNet18(\n",
    "\tnum_classes=num_classes,\n",
    "\tuse_adabn=True,\n",
    "\tuse_cbam=False,\n",
    "\tuse_proto=False,\n",
    "\tuse_rbn=False,\n",
    ").to(device)\n",
    "\n",
    "# (3) ResNet-50 + CBAM\n",
    "model_cbam = ResNet18(\n",
    "\tnum_classes=num_classes,\n",
    "\tuse_adabn=False,\n",
    "\tuse_cbam=True,\n",
    "\tuse_proto=False,\n",
    "\tuse_rbn=False,\n",
    ").to(device)\n",
    "\n",
    "# (4) ResNet-50 + Prototype Alignment\n",
    "model_proto = ResNet18(\n",
    "\tnum_classes=num_classes,\n",
    "\tuse_adabn=False,\n",
    "\tuse_cbam=False,\n",
    "\tuse_proto=True,\n",
    "\tuse_rbn=False,\n",
    ").to(device)\n",
    "\n",
    "# (5) ResNet-50 + Self-Correcting Block\n",
    "model_scb = ResNet18(\n",
    "\tnum_classes=num_classes,\n",
    "\tuse_adabn=False,\n",
    "\tuse_cbam=False,\n",
    "\tuse_proto=False,\n",
    "\tuse_rbn=False,\n",
    "\tuse_scb=True,\n",
    ").to(device)\n",
    "\n",
    "print(f\"Plain ResNet-50: {model_plain}\")\n",
    "print(f\"ResNet-50 with AdaBN: {model_adabn}\")\n",
    "print(f\"ResNet-50 with CBAM: {model_cbam}\")\n",
    "print(f\"ResNet-50 with Prototype Alignment: {model_proto}\")\n",
    "\"\"\"\n",
    "model_resnet18 = ResNet18(num_classes=10).to(device)\n",
    "model_resnet50 = ResNet50(num_classes=10).to(device)\n",
    "model_filmnet18_sgc = FiLMNet18_SGC(c_dim=512, num_classes=num_classes).to(device)\n",
    "model_filmnet50_sgc = FiLMNet50_SGC(c_dim=512, num_classes=1000).to(device)\n",
    "model_protonet18 = ProtoNet18(ResNet18, embedding_dim=512, num_classes=num_classes).to(device)\n",
    "model_protonet50 = ProtoNet18(ResNet50, embedding_dim=2048, num_classes=num_classes).to(device)\n",
    "print(model_resnet18)\n",
    "\"\"\"\n",
    "\n",
    "# geometric models, kind of\n",
    "\n",
    "model_topo_conv = TopoResNet18(num_classes=num_classes).to(device)\n",
    "model_simp_conv = ExpandedSimplicialResNet(num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5363b",
   "metadata": {},
   "source": [
    "### 2.1) Model optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2921447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optim_resnet18  = optim.AdamW(model_resnet18.parameters(), lr=lr, weight_decay=5e-4)\n",
    "#optim_resnet50  = optim.AdamW(model_resnet50.parameters(), lr=lr, weight_decay=5e-4)\n",
    "#optim_protonet18 = optim.AdamW(model_protonet18.parameters(), lr=lr, weight_decay=5e-4)\n",
    "#optim_filmnet18_sgc = optim.AdamW(model_filmnet18_sgc.parameters(), lr=lr, weight_decay=5e-4)\n",
    "#optim_filmnet50_sgc = optim.AdamW(model_filmnet50_sgc.parameters(), lr=lr, weight_decay=5e-4)\n",
    "optim_plain  = optim.SGD(model_plain.parameters(),  lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optim_adabn  = optim.SGD(model_adabn.parameters(),  lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optim_cbam   = optim.SGD(model_cbam.parameters(),   lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optim_scb    = optim.SGD(model_scb.parameters(),   lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optim_proto  = optim.SGD(model_proto.parameters(),  lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optim_topo_conv = optim.SGD(model_topo_conv.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optim_simp_conv = optim.SGD(model_simp_conv.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "# A dictionary to store (model, optimizer) pairs for easy looping:\n",
    "baseline_dict = {\n",
    "#    \"ResNet18\": (model_resnet18, optim_resnet18),\n",
    "#    \"ResNet50\": (model_resnet50, optim_resnet50),\n",
    "#\t\"ProtoNet18\": (model_protonet18, optim_protonet18),\n",
    "#\t\"Proto\"   : (model_proto, optim_proto),\n",
    "#\t\"Plain\"   : (model_plain, optim_plain),\n",
    "#\t\"AdaBN\"   : (model_adabn, optim_adabn),\n",
    "#\t\"CBAM\"    : (model_cbam,  optim_cbam ),\n",
    "#\t\"TopoConv\": (model_topo_conv, optim_topo_conv),\n",
    "#\t\"SimpConv\": (model_simp_conv, optim_simp_conv),\n",
    "\t\"SCB\"     : (model_scb, optim_scb),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ed0d7",
   "metadata": {},
   "source": [
    "## 3) Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7acab78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training baseline: TopoConv ===\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_001_TopoConv.pt\n",
      "[TopoConv][Epoch 1/100] train_loss=1.8262, train_acc=0.3235  val_loss=1.4857, val_acc=0.4408  (best=0.4408)  epoch_time=0h01m16s, ETA=2h06m07s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_002_TopoConv.pt\n",
      "[TopoConv][Epoch 2/100] train_loss=1.5600, train_acc=0.4301  val_loss=1.3063, val_acc=0.5215  (best=0.5215)  epoch_time=0h01m14s, ETA=2h01m07s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_003_TopoConv.pt\n",
      "[TopoConv][Epoch 3/100] train_loss=1.4291, train_acc=0.4839  val_loss=1.1719, val_acc=0.5763  (best=0.5763)  epoch_time=0h01m13s, ETA=1h59m27s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_004_TopoConv.pt\n",
      "[TopoConv][Epoch 4/100] train_loss=1.3225, train_acc=0.5262  val_loss=1.1523, val_acc=0.5943  (best=0.5943)  epoch_time=0h01m13s, ETA=1h56m57s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_005_TopoConv.pt\n",
      "[TopoConv][Epoch 5/100] train_loss=1.2398, train_acc=0.5578  val_loss=1.0101, val_acc=0.6425  (best=0.6425)  epoch_time=0h01m14s, ETA=1h57m30s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_006_TopoConv.pt\n",
      "[TopoConv][Epoch 6/100] train_loss=1.1704, train_acc=0.5831  val_loss=0.9352, val_acc=0.6703  (best=0.6703)  epoch_time=0h01m13s, ETA=1h55m49s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_007_TopoConv.pt\n",
      "[TopoConv][Epoch 7/100] train_loss=1.1131, train_acc=0.6046  val_loss=0.8979, val_acc=0.6824  (best=0.6824)  epoch_time=0h01m13s, ETA=1h53m32s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_008_TopoConv.pt\n",
      "[TopoConv][Epoch 8/100] train_loss=1.0646, train_acc=0.6234  val_loss=0.8526, val_acc=0.7032  (best=0.7032)  epoch_time=0h01m13s, ETA=1h52m30s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_009_TopoConv.pt\n",
      "[TopoConv][Epoch 9/100] train_loss=1.0127, train_acc=0.6416  val_loss=0.8215, val_acc=0.7092  (best=0.7092)  epoch_time=0h01m14s, ETA=1h52m14s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_010_TopoConv.pt\n",
      "[TopoConv][Epoch 10/100] train_loss=0.9709, train_acc=0.6586  val_loss=0.7916, val_acc=0.7204  (best=0.7204)  epoch_time=0h01m13s, ETA=1h50m51s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_011_TopoConv.pt\n",
      "[TopoConv][Epoch 11/100] train_loss=0.9342, train_acc=0.6718  val_loss=0.7457, val_acc=0.7351  (best=0.7351)  epoch_time=0h01m13s, ETA=1h48m59s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_012_TopoConv.pt\n",
      "[TopoConv][Epoch 12/100] train_loss=0.9023, train_acc=0.6834  val_loss=0.7324, val_acc=0.7497  (best=0.7497)  epoch_time=0h01m15s, ETA=1h50m40s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_013_TopoConv.pt\n",
      "[TopoConv][Epoch 13/100] train_loss=0.8772, train_acc=0.6918  val_loss=0.6514, val_acc=0.7736  (best=0.7736)  epoch_time=0h01m14s, ETA=1h48m14s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_014_TopoConv.pt\n",
      "[TopoConv][Epoch 14/100] train_loss=0.8399, train_acc=0.7064  val_loss=0.6507, val_acc=0.7753  (best=0.7753)  epoch_time=0h01m14s, ETA=1h46m27s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_015_TopoConv.pt\n",
      "[TopoConv][Epoch 15/100] train_loss=0.8258, train_acc=0.7117  val_loss=0.6464, val_acc=0.7811  (best=0.7811)  epoch_time=0h01m14s, ETA=1h45m19s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_016_TopoConv.pt\n",
      "[TopoConv][Epoch 16/100] train_loss=0.7946, train_acc=0.7207  val_loss=0.6280, val_acc=0.7851  (best=0.7851)  epoch_time=0h01m14s, ETA=1h44m19s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_017_TopoConv.pt\n",
      "[TopoConv][Epoch 17/100] train_loss=0.7753, train_acc=0.7310  val_loss=0.5891, val_acc=0.7965  (best=0.7965)  epoch_time=0h01m14s, ETA=1h43m08s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_018_TopoConv.pt\n",
      "[TopoConv][Epoch 18/100] train_loss=0.7613, train_acc=0.7340  val_loss=0.6234, val_acc=0.7870  (best=0.7965)  epoch_time=0h01m14s, ETA=1h41m40s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_019_TopoConv.pt\n",
      "[TopoConv][Epoch 19/100] train_loss=0.7467, train_acc=0.7399  val_loss=0.5817, val_acc=0.8037  (best=0.8037)  epoch_time=0h01m14s, ETA=1h40m57s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_020_TopoConv.pt\n",
      "[TopoConv][Epoch 20/100] train_loss=0.7302, train_acc=0.7458  val_loss=0.5506, val_acc=0.8099  (best=0.8099)  epoch_time=0h01m14s, ETA=1h39m03s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_021_TopoConv.pt\n",
      "[TopoConv][Epoch 21/100] train_loss=0.7135, train_acc=0.7525  val_loss=0.5637, val_acc=0.8069  (best=0.8099)  epoch_time=0h01m13s, ETA=1h37m23s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_022_TopoConv.pt\n",
      "[TopoConv][Epoch 22/100] train_loss=0.6990, train_acc=0.7561  val_loss=0.5595, val_acc=0.8095  (best=0.8099)  epoch_time=0h01m13s, ETA=1h36m01s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_023_TopoConv.pt\n",
      "[TopoConv][Epoch 23/100] train_loss=0.6811, train_acc=0.7615  val_loss=0.5360, val_acc=0.8180  (best=0.8180)  epoch_time=0h01m13s, ETA=1h34m51s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_024_TopoConv.pt\n",
      "[TopoConv][Epoch 24/100] train_loss=0.6728, train_acc=0.7646  val_loss=0.5306, val_acc=0.8204  (best=0.8204)  epoch_time=0h01m13s, ETA=1h33m29s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_025_TopoConv.pt\n",
      "[TopoConv][Epoch 25/100] train_loss=0.6586, train_acc=0.7702  val_loss=0.5209, val_acc=0.8233  (best=0.8233)  epoch_time=0h01m13s, ETA=1h32m12s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_026_TopoConv.pt\n",
      "[TopoConv][Epoch 26/100] train_loss=0.6495, train_acc=0.7737  val_loss=0.5076, val_acc=0.8272  (best=0.8272)  epoch_time=0h01m13s, ETA=1h31m14s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_027_TopoConv.pt\n",
      "[TopoConv][Epoch 27/100] train_loss=0.6367, train_acc=0.7798  val_loss=0.5078, val_acc=0.8271  (best=0.8272)  epoch_time=0h01m13s, ETA=1h29m50s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_028_TopoConv.pt\n",
      "[TopoConv][Epoch 28/100] train_loss=0.6242, train_acc=0.7830  val_loss=0.4952, val_acc=0.8322  (best=0.8322)  epoch_time=0h01m14s, ETA=1h28m53s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_029_TopoConv.pt\n",
      "[TopoConv][Epoch 29/100] train_loss=0.6233, train_acc=0.7820  val_loss=0.4853, val_acc=0.8354  (best=0.8354)  epoch_time=0h01m13s, ETA=1h27m08s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_030_TopoConv.pt\n",
      "[TopoConv][Epoch 30/100] train_loss=0.6113, train_acc=0.7864  val_loss=0.5047, val_acc=0.8238  (best=0.8354)  epoch_time=0h01m13s, ETA=1h26m19s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_031_TopoConv.pt\n",
      "[TopoConv][Epoch 31/100] train_loss=0.5995, train_acc=0.7895  val_loss=0.4780, val_acc=0.8401  (best=0.8401)  epoch_time=0h01m14s, ETA=1h25m08s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_032_TopoConv.pt\n",
      "[TopoConv][Epoch 32/100] train_loss=0.5903, train_acc=0.7944  val_loss=0.4612, val_acc=0.8402  (best=0.8402)  epoch_time=0h01m14s, ETA=1h23m59s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_033_TopoConv.pt\n",
      "[TopoConv][Epoch 33/100] train_loss=0.5869, train_acc=0.7959  val_loss=0.4565, val_acc=0.8438  (best=0.8438)  epoch_time=0h01m14s, ETA=1h22m50s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_034_TopoConv.pt\n",
      "[TopoConv][Epoch 34/100] train_loss=0.5787, train_acc=0.7983  val_loss=0.4688, val_acc=0.8402  (best=0.8438)  epoch_time=0h01m13s, ETA=1h21m12s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_035_TopoConv.pt\n",
      "[TopoConv][Epoch 35/100] train_loss=0.5703, train_acc=0.8019  val_loss=0.4735, val_acc=0.8385  (best=0.8438)  epoch_time=0h01m14s, ETA=1h20m55s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_036_TopoConv.pt\n",
      "[TopoConv][Epoch 36/100] train_loss=0.5643, train_acc=0.8021  val_loss=0.4597, val_acc=0.8433  (best=0.8438)  epoch_time=0h01m14s, ETA=1h19m39s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_037_TopoConv.pt\n",
      "[TopoConv][Epoch 37/100] train_loss=0.5542, train_acc=0.8098  val_loss=0.4603, val_acc=0.8408  (best=0.8438)  epoch_time=0h01m14s, ETA=1h18m20s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_038_TopoConv.pt\n",
      "[TopoConv][Epoch 38/100] train_loss=0.5493, train_acc=0.8109  val_loss=0.4347, val_acc=0.8473  (best=0.8473)  epoch_time=0h01m13s, ETA=1h16m09s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_039_TopoConv.pt\n",
      "[TopoConv][Epoch 39/100] train_loss=0.5458, train_acc=0.8098  val_loss=0.4531, val_acc=0.8478  (best=0.8478)  epoch_time=0h01m14s, ETA=1h15m41s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_040_TopoConv.pt\n",
      "[TopoConv][Epoch 40/100] train_loss=0.5395, train_acc=0.8089  val_loss=0.4303, val_acc=0.8548  (best=0.8548)  epoch_time=0h01m14s, ETA=1h14m12s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_041_TopoConv.pt\n",
      "[TopoConv][Epoch 41/100] train_loss=0.5326, train_acc=0.8146  val_loss=0.4401, val_acc=0.8505  (best=0.8548)  epoch_time=0h01m13s, ETA=1h12m38s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_042_TopoConv.pt\n",
      "[TopoConv][Epoch 42/100] train_loss=0.5194, train_acc=0.8198  val_loss=0.4367, val_acc=0.8536  (best=0.8548)  epoch_time=0h01m14s, ETA=1h11m39s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_043_TopoConv.pt\n",
      "[TopoConv][Epoch 43/100] train_loss=0.5184, train_acc=0.8183  val_loss=0.4268, val_acc=0.8543  (best=0.8548)  epoch_time=0h01m14s, ETA=1h10m37s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_044_TopoConv.pt\n",
      "[TopoConv][Epoch 44/100] train_loss=0.5157, train_acc=0.8205  val_loss=0.4441, val_acc=0.8515  (best=0.8548)  epoch_time=0h01m13s, ETA=1h08m54s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_045_TopoConv.pt\n",
      "[TopoConv][Epoch 45/100] train_loss=0.5064, train_acc=0.8225  val_loss=0.4274, val_acc=0.8560  (best=0.8560)  epoch_time=0h01m14s, ETA=1h07m56s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_046_TopoConv.pt\n",
      "[TopoConv][Epoch 46/100] train_loss=0.5049, train_acc=0.8245  val_loss=0.4338, val_acc=0.8590  (best=0.8590)  epoch_time=0h01m15s, ETA=1h07m38s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_047_TopoConv.pt\n",
      "[TopoConv][Epoch 47/100] train_loss=0.4965, train_acc=0.8273  val_loss=0.4050, val_acc=0.8631  (best=0.8631)  epoch_time=0h01m14s, ETA=1h05m43s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_048_TopoConv.pt\n",
      "[TopoConv][Epoch 48/100] train_loss=0.4973, train_acc=0.8254  val_loss=0.4148, val_acc=0.8603  (best=0.8631)  epoch_time=0h01m15s, ETA=1h05m39s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_049_TopoConv.pt\n",
      "[TopoConv][Epoch 49/100] train_loss=0.4893, train_acc=0.8288  val_loss=0.4255, val_acc=0.8587  (best=0.8631)  epoch_time=0h01m14s, ETA=1h03m31s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_050_TopoConv.pt\n",
      "[TopoConv][Epoch 50/100] train_loss=0.4802, train_acc=0.8314  val_loss=0.4136, val_acc=0.8603  (best=0.8631)  epoch_time=0h01m14s, ETA=1h02m12s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_051_TopoConv.pt\n",
      "[TopoConv][Epoch 51/100] train_loss=0.4797, train_acc=0.8304  val_loss=0.4077, val_acc=0.8649  (best=0.8649)  epoch_time=0h01m14s, ETA=1h00m47s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_052_TopoConv.pt\n",
      "[TopoConv][Epoch 52/100] train_loss=0.4739, train_acc=0.8342  val_loss=0.3925, val_acc=0.8726  (best=0.8726)  epoch_time=0h01m15s, ETA=1h00m36s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_053_TopoConv.pt\n",
      "[TopoConv][Epoch 53/100] train_loss=0.4752, train_acc=0.8328  val_loss=0.3922, val_acc=0.8664  (best=0.8726)  epoch_time=0h01m15s, ETA=0h58m53s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_054_TopoConv.pt\n",
      "[TopoConv][Epoch 54/100] train_loss=0.4705, train_acc=0.8357  val_loss=0.3902, val_acc=0.8683  (best=0.8726)  epoch_time=0h01m15s, ETA=0h58m14s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_055_TopoConv.pt\n",
      "[TopoConv][Epoch 55/100] train_loss=0.4621, train_acc=0.8397  val_loss=0.3943, val_acc=0.8671  (best=0.8726)  epoch_time=0h01m14s, ETA=0h55m46s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_056_TopoConv.pt\n",
      "[TopoConv][Epoch 56/100] train_loss=0.4554, train_acc=0.8417  val_loss=0.4057, val_acc=0.8651  (best=0.8726)  epoch_time=0h01m16s, ETA=0h55m52s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_057_TopoConv.pt\n",
      "[TopoConv][Epoch 57/100] train_loss=0.4532, train_acc=0.8413  val_loss=0.4273, val_acc=0.8603  (best=0.8726)  epoch_time=0h01m14s, ETA=0h53m14s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_058_TopoConv.pt\n",
      "[TopoConv][Epoch 58/100] train_loss=0.4507, train_acc=0.8441  val_loss=0.3906, val_acc=0.8691  (best=0.8726)  epoch_time=0h01m14s, ETA=0h52m02s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_059_TopoConv.pt\n",
      "[TopoConv][Epoch 59/100] train_loss=0.4460, train_acc=0.8435  val_loss=0.4015, val_acc=0.8687  (best=0.8726)  epoch_time=0h01m14s, ETA=0h50m46s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_060_TopoConv.pt\n",
      "[TopoConv][Epoch 60/100] train_loss=0.4436, train_acc=0.8453  val_loss=0.3769, val_acc=0.8715  (best=0.8726)  epoch_time=0h01m14s, ETA=0h49m34s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_061_TopoConv.pt\n",
      "[TopoConv][Epoch 61/100] train_loss=0.4433, train_acc=0.8452  val_loss=0.4015, val_acc=0.8660  (best=0.8726)  epoch_time=0h01m14s, ETA=0h48m37s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_062_TopoConv.pt\n",
      "[TopoConv][Epoch 62/100] train_loss=0.4391, train_acc=0.8457  val_loss=0.4151, val_acc=0.8601  (best=0.8726)  epoch_time=0h01m14s, ETA=0h47m17s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_063_TopoConv.pt\n",
      "[TopoConv][Epoch 63/100] train_loss=0.4366, train_acc=0.8473  val_loss=0.4250, val_acc=0.8583  (best=0.8726)  epoch_time=0h01m14s, ETA=0h46m01s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_064_TopoConv.pt\n",
      "[TopoConv][Epoch 64/100] train_loss=0.4316, train_acc=0.8489  val_loss=0.3892, val_acc=0.8703  (best=0.8726)  epoch_time=0h07m08s, ETA=4h17m20s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_065_TopoConv.pt\n",
      "[TopoConv][Epoch 65/100] train_loss=0.4235, train_acc=0.8539  val_loss=0.4007, val_acc=0.8700  (best=0.8726)  epoch_time=0h23m07s, ETA=13h29m34s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_066_TopoConv.pt\n",
      "[TopoConv][Epoch 66/100] train_loss=0.4811, train_acc=0.8332  val_loss=0.4000, val_acc=0.8655  (best=0.8726)  epoch_time=1h18m10s, ETA=44h18m11s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_067_TopoConv.pt\n",
      "[TopoConv][Epoch 67/100] train_loss=0.4411, train_acc=0.8467  val_loss=0.3879, val_acc=0.8684  (best=0.8726)  epoch_time=0h01m15s, ETA=0h41m41s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_068_TopoConv.pt\n",
      "[TopoConv][Epoch 68/100] train_loss=0.4300, train_acc=0.8484  val_loss=0.3954, val_acc=0.8690  (best=0.8726)  epoch_time=0h01m15s, ETA=0h40m03s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_069_TopoConv.pt\n",
      "[TopoConv][Epoch 69/100] train_loss=0.4163, train_acc=0.8563  val_loss=0.3866, val_acc=0.8705  (best=0.8726)  epoch_time=0h01m15s, ETA=0h39m15s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_070_TopoConv.pt\n",
      "[TopoConv][Epoch 70/100] train_loss=0.4161, train_acc=0.8552  val_loss=0.4048, val_acc=0.8676  (best=0.8726)  epoch_time=0h01m15s, ETA=0h37m50s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_071_TopoConv.pt\n",
      "[TopoConv][Epoch 71/100] train_loss=0.4105, train_acc=0.8557  val_loss=0.3659, val_acc=0.8777  (best=0.8777)  epoch_time=0h01m15s, ETA=0h36m34s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_072_TopoConv.pt\n",
      "[TopoConv][Epoch 72/100] train_loss=0.4107, train_acc=0.8560  val_loss=0.3846, val_acc=0.8706  (best=0.8777)  epoch_time=0h01m14s, ETA=0h34m59s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_073_TopoConv.pt\n",
      "[TopoConv][Epoch 73/100] train_loss=0.4022, train_acc=0.8604  val_loss=0.3812, val_acc=0.8741  (best=0.8777)  epoch_time=0h01m14s, ETA=0h33m36s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_074_TopoConv.pt\n",
      "[TopoConv][Epoch 74/100] train_loss=0.4023, train_acc=0.8608  val_loss=0.3813, val_acc=0.8738  (best=0.8777)  epoch_time=0h01m14s, ETA=0h32m20s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_075_TopoConv.pt\n",
      "[TopoConv][Epoch 75/100] train_loss=0.4012, train_acc=0.8596  val_loss=0.3673, val_acc=0.8762  (best=0.8777)  epoch_time=0h01m14s, ETA=0h31m04s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_076_TopoConv.pt\n",
      "[TopoConv][Epoch 76/100] train_loss=0.3950, train_acc=0.8615  val_loss=0.3856, val_acc=0.8715  (best=0.8777)  epoch_time=0h01m15s, ETA=0h30m15s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_077_TopoConv.pt\n",
      "[TopoConv][Epoch 77/100] train_loss=0.3903, train_acc=0.8626  val_loss=0.3765, val_acc=0.8763  (best=0.8777)  epoch_time=0h01m15s, ETA=0h28m48s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_078_TopoConv.pt\n",
      "[TopoConv][Epoch 78/100] train_loss=0.3907, train_acc=0.8640  val_loss=0.3773, val_acc=0.8746  (best=0.8777)  epoch_time=0h01m18s, ETA=0h28m57s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_079_TopoConv.pt\n",
      "[TopoConv][Epoch 79/100] train_loss=0.3887, train_acc=0.8648  val_loss=0.3858, val_acc=0.8720  (best=0.8777)  epoch_time=0h01m15s, ETA=0h26m29s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_080_TopoConv.pt\n",
      "[TopoConv][Epoch 80/100] train_loss=0.3827, train_acc=0.8655  val_loss=0.3596, val_acc=0.8781  (best=0.8781)  epoch_time=0h01m15s, ETA=0h25m01s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_081_TopoConv.pt\n",
      "[TopoConv][Epoch 81/100] train_loss=0.3831, train_acc=0.8654  val_loss=0.3622, val_acc=0.8805  (best=0.8805)  epoch_time=0h01m15s, ETA=0h24m00s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_082_TopoConv.pt\n",
      "[TopoConv][Epoch 82/100] train_loss=0.3778, train_acc=0.8671  val_loss=0.3768, val_acc=0.8735  (best=0.8805)  epoch_time=0h01m15s, ETA=0h22m32s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_083_TopoConv.pt\n",
      "[TopoConv][Epoch 83/100] train_loss=0.3762, train_acc=0.8675  val_loss=0.3726, val_acc=0.8765  (best=0.8805)  epoch_time=0h01m16s, ETA=0h21m43s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_084_TopoConv.pt\n",
      "[TopoConv][Epoch 84/100] train_loss=0.3785, train_acc=0.8692  val_loss=0.3612, val_acc=0.8820  (best=0.8820)  epoch_time=0h01m15s, ETA=0h20m02s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_085_TopoConv.pt\n",
      "[TopoConv][Epoch 85/100] train_loss=0.3717, train_acc=0.8709  val_loss=0.3557, val_acc=0.8835  (best=0.8835)  epoch_time=0h01m16s, ETA=0h19m06s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_086_TopoConv.pt\n",
      "[TopoConv][Epoch 86/100] train_loss=0.3709, train_acc=0.8695  val_loss=0.3596, val_acc=0.8810  (best=0.8835)  epoch_time=0h01m17s, ETA=0h18m07s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_087_TopoConv.pt\n",
      "[TopoConv][Epoch 87/100] train_loss=0.3698, train_acc=0.8714  val_loss=0.3629, val_acc=0.8814  (best=0.8835)  epoch_time=0h01m15s, ETA=0h16m15s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_088_TopoConv.pt\n",
      "[TopoConv][Epoch 88/100] train_loss=0.3712, train_acc=0.8710  val_loss=0.3704, val_acc=0.8808  (best=0.8835)  epoch_time=0h01m18s, ETA=0h15m41s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_089_TopoConv.pt\n",
      "[TopoConv][Epoch 89/100] train_loss=0.3624, train_acc=0.8723  val_loss=0.3765, val_acc=0.8788  (best=0.8835)  epoch_time=0h01m16s, ETA=0h14m00s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_090_TopoConv.pt\n",
      "[TopoConv][Epoch 90/100] train_loss=0.3654, train_acc=0.8715  val_loss=0.3495, val_acc=0.8878  (best=0.8878)  epoch_time=0h01m14s, ETA=0h12m27s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_091_TopoConv.pt\n",
      "[TopoConv][Epoch 91/100] train_loss=0.3551, train_acc=0.8743  val_loss=0.3575, val_acc=0.8826  (best=0.8878)  epoch_time=0h01m15s, ETA=0h11m21s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_092_TopoConv.pt\n",
      "[TopoConv][Epoch 92/100] train_loss=0.3614, train_acc=0.8741  val_loss=0.3637, val_acc=0.8813  (best=0.8878)  epoch_time=0h01m15s, ETA=0h10m05s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_093_TopoConv.pt\n",
      "[TopoConv][Epoch 93/100] train_loss=0.3569, train_acc=0.8744  val_loss=0.3676, val_acc=0.8793  (best=0.8878)  epoch_time=0h01m16s, ETA=0h08m52s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_094_TopoConv.pt\n",
      "[TopoConv][Epoch 94/100] train_loss=0.3556, train_acc=0.8774  val_loss=0.3671, val_acc=0.8820  (best=0.8878)  epoch_time=0h01m15s, ETA=0h07m33s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_095_TopoConv.pt\n",
      "[TopoConv][Epoch 95/100] train_loss=0.3526, train_acc=0.8768  val_loss=0.3956, val_acc=0.8728  (best=0.8878)  epoch_time=0h01m14s, ETA=0h06m12s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_096_TopoConv.pt\n",
      "[TopoConv][Epoch 96/100] train_loss=0.3444, train_acc=0.8782  val_loss=0.3942, val_acc=0.8756  (best=0.8878)  epoch_time=0h01m15s, ETA=0h05m03s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_097_TopoConv.pt\n",
      "[TopoConv][Epoch 97/100] train_loss=0.3489, train_acc=0.8790  val_loss=0.3709, val_acc=0.8842  (best=0.8878)  epoch_time=0h01m15s, ETA=0h03m47s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_098_TopoConv.pt\n",
      "[TopoConv][Epoch 98/100] train_loss=0.3453, train_acc=0.8796  val_loss=0.3677, val_acc=0.8792  (best=0.8878)  epoch_time=0h01m15s, ETA=0h02m30s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_099_TopoConv.pt\n",
      "[TopoConv][Epoch 99/100] train_loss=0.3426, train_acc=0.8806  val_loss=0.3607, val_acc=0.8867  (best=0.8878)  epoch_time=0h01m14s, ETA=0h01m14s\n",
      "\n",
      "Batch idx: 1562 of 1563\n",
      "Saved checkpoint: checkpoints/ckpt_epoch_100_TopoConv.pt\n",
      "[TopoConv][Epoch 100/100] train_loss=0.3458, train_acc=0.8801  val_loss=0.3821, val_acc=0.8761  (best=0.8878)  epoch_time=0h01m15s, ETA=0h00m00s\n",
      "--- Finished TopoConv (total_time=3h49m26s) ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Track best validation accuracy for each baseline:\n",
    "best_val_acc = {name: 0.0 for name in baseline_dict.keys()}\n",
    "\n",
    "for name, (model, optim) in baseline_dict.items():\n",
    "\ttrain_model(name=name, model=model, optimizer=optim, train_loader=train_loader, test_loader=test_loader, \n",
    "\t\t\t\tcriterion=criterion, device=device, num_epochs=num_epochs)\n",
    "\n",
    "\n",
    "#train_protonet(name=\"ProtoNet\", model=model_protonet18, optimizer=optim_protonet18, train_loader=protonet_train_loader, test_loader=protonet_test_loader,\n",
    "#\t\t\tcriterion=criterion, device=device, num_epochs=num_epochs)\n",
    "\n",
    "#train_model(name=\"FilmNet50_SGC\", model=model_filmnet50_sgc, optimizer=optim_filmnet50_sgc, train_loader=train_t_imagenet_loader, test_loader=val_t_imagenet_loader,\n",
    "#\t\t\tcriterion=criterion, device=device, num_epochs=num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2cb595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e327993",
   "metadata": {},
   "source": [
    "### Save the models to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "530ba88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Dictionary mapping a humanreadable name  the actual nn.Module\\nmodels_to_save = {\\n\\t\"plain\":  model_plain,\\n\\t\"adabn\":  model_adabn,\\n\\t\"cbam\":   model_cbam,\\n\\t\"proto\":  model_proto,\\n}\\n\\n# Ensure the directory exists (in this case, were saving to the current working directory)\\nsave_dir = os.getcwd()\\nprint(f\"Saving models into: {save_dir}\")\\n\\nfor name, model in models_to_save.items():\\n\\t# Construct a filename like \"model_plain.pth\" or \"model_adabn.pth\"\\n\\tfilename = f\"model_{name}.pth\"\\n\\tfilepath = os.path.join(save_dir, filename)\\n\\n\\t# Save only the models state dict (weights + buffers)\\n\\ttorch.save(model.state_dict(), filepath)\\n\\tprint(f\" Saved {name} to {filename}\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Dictionary mapping a humanreadable name  the actual nn.Module\n",
    "models_to_save = {\n",
    "\t\"plain\":  model_plain,\n",
    "\t\"adabn\":  model_adabn,\n",
    "\t\"cbam\":   model_cbam,\n",
    "\t\"proto\":  model_proto,\n",
    "}\n",
    "\n",
    "# Ensure the directory exists (in this case, were saving to the current working directory)\n",
    "save_dir = os.getcwd()\n",
    "print(f\"Saving models into: {save_dir}\")\n",
    "\n",
    "for name, model in models_to_save.items():\n",
    "\t# Construct a filename like \"model_plain.pth\" or \"model_adabn.pth\"\n",
    "\tfilename = f\"model_{name}.pth\"\n",
    "\tfilepath = os.path.join(save_dir, filename)\n",
    "\n",
    "\t# Save only the models state dict (weights + buffers)\n",
    "\ttorch.save(model.state_dict(), filepath)\n",
    "\tprint(f\" Saved {name} to {filename}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4abecd",
   "metadata": {},
   "source": [
    "### Load models from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adcdbfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: /Users/codiri/University/Edinburgh/Lightweight-SCNNs/ckpt_epoch_100_TopoConv.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Directory to save the models\n",
    "save_dir = os.getcwd()  # Current working directory\n",
    "\n",
    "\n",
    "for name, (model, optim) in baseline_dict.items():\n",
    "\tpath = os.path.join(save_dir, f\"ckpt_epoch_100_{name}.pt\")\n",
    "\t#path = os.path.join(save_dir, f\"model_{name}.pth\")\n",
    "\tif os.path.exists(path):\n",
    "\t\tstate_dict = torch.load(path, map_location=device)\n",
    "\t\tmodel.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "\t\t#model.load_state_dict(torch.load(path, map_location=device))\n",
    "\t\t#model.to(device)  \n",
    "\n",
    "\t\tprint(f\"Loaded {name} model from {path}\")\n",
    "\n",
    "\telse:\n",
    "\t\tprint(f\"File not found: {path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72dfa7",
   "metadata": {},
   "source": [
    "### 3.1) Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c833953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TopoConv: Accuracy on Cifar10 val set = 87.61%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate total accuracy on val_t_imagenet_loader for all 4 models\n",
    "accuracies = {}\n",
    "\n",
    "for name, (model, optim) in baseline_dict.items():\n",
    "\tmodel.eval()\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor images, labels in test_loader:\n",
    "\t\t\timages = images.to(device)\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\t\t\tfeats, outputs = model(images)\n",
    "\t\t\t_, preds = outputs.max(dim=1)\n",
    "\t\t\tcorrect += (preds == labels).sum().item()\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\tacc = correct / total\n",
    "\taccuracies[name] = acc\n",
    "\tprint(f\"{name}: Accuracy on Cifar10 val set = {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feced7b",
   "metadata": {},
   "source": [
    "## 4) Evaluate model on CIFAR-10C dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "771cc68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating corruption: gaussian_noise (severity=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codiri/installs/miniconda3/envs/SCNN/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corruption = gaussian_noise  | TopoConv: 79.66%\n",
      "\n",
      "Evaluating corruption: shot_noise (severity=1)\n",
      "Corruption = shot_noise      | TopoConv: 83.28%\n",
      "\n",
      "Evaluating corruption: impulse_noise (severity=1)\n",
      "Corruption = impulse_noise   | TopoConv: 86.31%\n",
      "\n",
      "Evaluating corruption: defocus_blur (severity=1)\n",
      "Corruption = defocus_blur    | TopoConv: 86.89%\n",
      "\n",
      "Evaluating corruption: glass_blur (severity=1)\n",
      "Corruption = glass_blur      | TopoConv: 74.29%\n",
      "\n",
      "Evaluating corruption: motion_blur (severity=1)\n",
      "Corruption = motion_blur     | TopoConv: 81.31%\n",
      "\n",
      "Evaluating corruption: zoom_blur (severity=1)\n",
      "Corruption = zoom_blur       | TopoConv: 78.58%\n",
      "\n",
      "Evaluating corruption: snow (severity=1)\n",
      "Corruption = snow            | TopoConv: 84.19%\n",
      "\n",
      "Evaluating corruption: frost (severity=1)\n",
      "Corruption = frost           | TopoConv: 84.15%\n",
      "\n",
      "Evaluating corruption: fog (severity=1)\n",
      "Corruption = fog             | TopoConv: 86.96%\n",
      "\n",
      "Evaluating corruption: brightness (severity=1)\n",
      "Corruption = brightness      | TopoConv: 87.28%\n",
      "\n",
      "Evaluating corruption: contrast (severity=1)\n",
      "Corruption = contrast        | TopoConv: 86.67%\n",
      "\n",
      "Evaluating corruption: elastic_transform (severity=1)\n",
      "Corruption = elastic_transform | TopoConv: 80.71%\n",
      "\n",
      "Evaluating corruption: pixelate (severity=1)\n",
      "Corruption = pixelate        | TopoConv: 86.19%\n",
      "\n",
      "Evaluating corruption: jpeg_compression (severity=1)\n",
      "Corruption = jpeg_compression | TopoConv: 83.77%\n",
      "\n",
      "Average accuracy over all 15 corruptions (severity=1):\n",
      "  TopoConv    83.35%\n"
     ]
    }
   ],
   "source": [
    "severity = 1  # Severity level (1-5), where 1 is the least severe\n",
    "batch_size = 256\n",
    "\n",
    "# We'll store per-model, per-corruption accuracies here:\n",
    "results = { name: [] for name in baseline_dict.keys() }\n",
    "\n",
    "# For each corruption type, build a CIFAR10C loader and measure accuracy:\n",
    "for corruption in corruptions:\n",
    "\t# Create the CIFAR-10-C dataset for this corruption & severity\n",
    "\tprint(f\"\\nEvaluating corruption: {corruption} (severity={severity})\")\n",
    "\tds_c = CIFAR10C(\n",
    "\t\tdata_dir=CIFAR10C_ROOT,\n",
    "\t\tcorruption=corruption,\n",
    "\t\tseverity=severity,\n",
    "\t\ttransform=test_transform\n",
    "\t)\n",
    "\tloader_c = DataLoader(ds_c,\n",
    "\t\t\t\t\t\t  batch_size=batch_size,\n",
    "\t\t\t\t\t\t  shuffle=False,\n",
    "\t\t\t\t\t\t  num_workers=2,\n",
    "\t\t\t\t\t\t  pin_memory=True)\n",
    "\n",
    "\t# For each model, run inference on this loader and compute accuracy\n",
    "\tfor name, (model, optim) in baseline_dict.items():\n",
    "\t\t#print(f\"  Evaluating {name}...\", end='\\n')\n",
    "\t\tmodel.eval()  # Set model to evaluation mode\n",
    "\t\tcorrect = 0\n",
    "\t\ttotal = 0\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor images, labels in loader_c:\n",
    "\t\t\t\timages = images.to(device)\n",
    "\t\t\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\t\t\t_, outputs = model(images)               # (B, 10)\n",
    "\t\t\t\t_, preds = outputs.max(dim=1)         # (B,)\n",
    "\t\t\t\tcorrect += (preds == labels).sum().item()\n",
    "\t\t\t\ttotal += labels.size(0)\n",
    "\t\t\t\t#print(f\"  {name}: {correct}/{total} ({100 * correct / total:.2f}%)\", end='\\r')\n",
    "\n",
    "\t\tacc = correct / total\n",
    "\t\tresults[name].append(acc)\n",
    "\n",
    "\tprint(f\"Corruption = {corruption:<15} | \"\n",
    "\t\t  + \"  \".join([f\"{n}: {results[n][-1]*100:5.2f}%\" for n in baseline_dict.keys()]) )\n",
    "\n",
    "# 5) Summarize average across all corruptions\n",
    "# \n",
    "\n",
    "print(\"\\nAverage accuracy over all 15 corruptions (severity=1):\")\n",
    "for name in baseline_dict.keys():\n",
    "\tavg_acc = np.mean(results[name])\n",
    "\tprint(f\"  {name:<5}    {avg_acc*100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46281fc1",
   "metadata": {},
   "source": [
    "### 4.1) Load concatenated CIFAR-10C dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6aa1c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR-10-C corruption arrays...\n",
      "Corruption: gaussian_noise, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: shot_noise, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: impulse_noise, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: defocus_blur, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: glass_blur, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: motion_blur, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: zoom_blur, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: snow, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: frost, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: fog, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: brightness, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: contrast, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: elastic_transform, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: pixelate, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Corruption: jpeg_compression, shape: (50000, 32, 32, 3), dtype: uint8\n",
      "Concatenated array shape: (750000, 32, 32, 3), dtype: uint8\n",
      "Labels shape: (50000,), dtype: uint8\n",
      "All labels shape: (750000,), dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "# Load and inspect CIFAR-10-C corruption arrays\n",
    "print(\"Loading CIFAR-10-C corruption arrays...\")\n",
    "arr = []\n",
    "\n",
    "\n",
    "for corruption in corruptions:\n",
    "\tarr_c = np.load(os.path.join(CIFAR10C_ROOT, f\"{corruption}.npy\"))\n",
    "\tprint(f\"Corruption: {corruption}, shape: {arr_c.shape}, dtype: {arr_c.dtype}\")\n",
    "\n",
    "\t# concatanate all corruption arrays into a single tensor\n",
    "\tarr.append(arr_c)\n",
    "\n",
    "arr = np.concatenate(arr, axis=0)\n",
    "print(f\"Concatenated array shape: {arr.shape}, dtype: {arr.dtype}\")\n",
    "\n",
    "labels = np.load(os.path.join(CIFAR10C_ROOT, \"labels.npy\"))\n",
    "print(f\"Labels shape: {labels.shape}, dtype: {labels.dtype}\")\n",
    "all_labels = np.concatenate([labels] * len(corruptions), axis=0)\n",
    "print(f\"All labels shape: {all_labels.shape}, dtype: {all_labels.dtype}\")\n",
    "\n",
    "# Create a daatset from the concatenated array\n",
    "ds_cifar10c = ImgClassificationDataset(\n",
    "\tdata=arr,\n",
    "\tlabels=all_labels,\n",
    "\ttransform=test_transform\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the CIFAR-10-C dataset\n",
    "loader_cifar10c = DataLoader(\n",
    "\tds_cifar10c,\n",
    "\tbatch_size=batch_size,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa7179",
   "metadata": {},
   "source": [
    "### 4.2) Compute ECE over entire CIFAR-10-C dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4972af11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating TopoConv on CIFAR-10-C dataset...\n",
      "Processed 515680 / 750000 images\n",
      "ECE over CIFAR-10-C: 10.29%\n",
      "Accuracy over CIFAR-10-C: 73.69%\n",
      "TopoConv - Accuracy: 73.69%, ECE: 0.1029\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy and ECE for each model on the CIFAR-10-C dataset\n",
    "acc_list = []\n",
    "ece_list = []\n",
    "\n",
    "for name, (model, optim) in baseline_dict.items():\n",
    "\tprint(f\"\\nEvaluating {name} on CIFAR-10-C dataset...\")\n",
    "\tece, acc = evaluate_model(model=model,\n",
    "\t\t\t\t   loader=loader_cifar10c,\n",
    "\t\t\t\t   device=device)\n",
    "\tacc_list.append(acc)\n",
    "\tece_list.append(ece)\n",
    "\tprint(f\"{name} - Accuracy: {acc*100:.2f}%, ECE: {ece:.4f}\")\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe7648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
